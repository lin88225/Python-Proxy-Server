The Request-Response Cycle
The proxy acts as a transparent intermediary.

Interception: The proxy listens on Port 4000. When a Web Client sends an HTTP Request, the proxy accepts the TCP connection.

Validation & Caching: The proxy checks if the URL is in the blocked_urls set. If allowed, it checks the local filesystem (MD5-hashed filenames) for a cached copy of the response.

Relay: If the item is not cached, the proxy initiates a new socket connection to the destination Web Server (usually on Port 80 for HTTP or 443 for HTTPS).

Completion: The proxy relays the data back to the browser and closes the connection.

Thread Safety and Concurrency

Threaded Server: To handle multiple requests simultaneously, each connection is wrapped in a threading.Thread object.

Resource Locking: A threading.Lock() is utilized when accessing the blocked_urls set. This ensures that the Admin Console thread and the Request Handler threads do not attempt to modify or read the list at the exact same microsecond, preventing race conditions.

3. macOS Specific Verification
Activity Monitor: You can open "Activity Monitor" on your Mac to see the multiple threads being spawned by your Python process as you load a complex webpage.

Timing Data: In your video demonstration, point out the RTT (Round Trip Time) printed in your console. You will notice that cached requests often show RTTs of 0.5ms to 2.0ms, while fresh fetches will be 50ms to 200ms. This is your proof of efficiency.